{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom Filters\n",
    "\n",
    "A bloom filter is a set data structure with constant $\\Omicron(1)$ lookup performance that has no false negatives (always detects memberships if actually a member) but can have false positives (can detect membership but actually not a member), along with $\\Omicron(1)$ insert complexity.\n",
    "\n",
    "It specializes in having a constant memory cost, of which the size directly corrosponds with the false positive rate assuming a perfect hashing function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BloomFilter(n=2996 bytes, #=1000, k=17) fp=9.995548181145193e-06\n",
      "BloomFilter(n=2997 bytes, #=1000, k=16) fp=9.98850733116421e-06\n",
      "32984\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import scipy.optimize as opt\n",
    "import sys\n",
    "\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "def random_string(min_length: int = 9, max_length: int = 18):\n",
    "    length = random.randint(min_length, max_length)\n",
    "    letters = string.ascii_letters + string.digits\n",
    "    return \"\".join(random.choices(letters, k=length))\n",
    "\n",
    "\n",
    "class BloomFilter:\n",
    "    # filter memory\n",
    "\n",
    "    memory: bytearray\n",
    "    # number of hash functions\n",
    "\n",
    "    k: int\n",
    "    # number of items in the filter\n",
    "    items: int\n",
    "\n",
    "    # bytes of each hash function output\n",
    "    BLOCK_SIZE: int = 4\n",
    "\n",
    "    def __init__(self, size: int = 1000, k: int = 16):\n",
    "        \"\"\"Creates the filter with *size* bytes of memory and *k* hash functions\"\"\"\n",
    "\n",
    "        self.memory = bytearray(size)\n",
    "        self.k = k\n",
    "        self.items = 0\n",
    "\n",
    "    def hash(self, data: bytes) -> bytes:\n",
    "        \"\"\"Returns the hash of length k*BLOCK for the data *data*\"\"\"\n",
    "\n",
    "        h = hashlib.shake_256()\n",
    "        h.update(data)\n",
    "        return h.digest(self.BLOCK_SIZE * self.k)\n",
    "\n",
    "    def indices(self, data: bytes) -> Iterator[int]:\n",
    "        \"\"\"Returns a iterator of set indices for the data *data*\"\"\"\n",
    "        digest = self.hash(data)\n",
    "\n",
    "        for i in range(self.k):\n",
    "            pos = int.from_bytes(\n",
    "                digest[self.BLOCK_SIZE * i : self.BLOCK_SIZE * (i + 1)], \"little\"\n",
    "            ) % (8 * len(self.memory))\n",
    "            yield pos\n",
    "\n",
    "    def add(self, data: bytes):\n",
    "        \"\"\"Add *data* to the filter\"\"\"\n",
    "        for pos in self.indices(data):\n",
    "            self.memory[pos // 8] |= 1 << (pos % 8)\n",
    "\n",
    "        self.items += 1\n",
    "\n",
    "    def __contains__(self, item: bytes):\n",
    "        \"\"\"Checks if *data* is likely in the filter\"\"\"\n",
    "        for pos in self.indices(item):\n",
    "            if self.memory[pos // 8] & (1 << (pos % 8)) == 0:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def fp_rate(self) -> float:\n",
    "        \"\"\"Returns the probability that an element not in the filter is detected to be in the filter\"\"\"\n",
    "\n",
    "        n = 8 * len(self.memory)\n",
    "        m = self.items\n",
    "        k = self.k\n",
    "\n",
    "        return (1 - (1 - 1 / n) ** (k * m)) ** k\n",
    "\n",
    "    @staticmethod\n",
    "    def least_memory(max_fp_rate: float, max_items: int, k: int) -> int:\n",
    "        \"\"\"Returns the least memory in bytes needed to store a max of *max_item* items with *max_fp_rate*\"\"\"\n",
    "        occ_rate = -math.log(1 - max_fp_rate ** (1 / k)) / k\n",
    "        mem = max_items / occ_rate\n",
    "        return int(mem // 8 + 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def best_k(max_fp_rate: float) -> int:\n",
    "        res = opt.minimize_scalar(\n",
    "            lambda k: -k / math.log(1 - max_fp_rate ** (1 / k)), bounds=(0.5, 64)\n",
    "        )\n",
    "        if not res.success:\n",
    "            k = 16\n",
    "        else:\n",
    "            k = math.ceil(res.x)\n",
    "\n",
    "        return k\n",
    "\n",
    "    @staticmethod\n",
    "    def create_filter(max_fp_rate: float, max_items: int, k: int = None):\n",
    "        if k is None:\n",
    "            k = BloomFilter.best_k(max_fp_rate)\n",
    "\n",
    "        mem = BloomFilter.least_memory(max_fp_rate, max_items, k)\n",
    "        return BloomFilter(mem, k)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"BloomFilter(n={len(self.memory)} bytes, #={self.items}, k={self.k})\"\n",
    "\n",
    "\n",
    "# fil = BloomFilter.create_filter(0.001, 1000, 8)\n",
    "\n",
    "# all_strings = set()\n",
    "\n",
    "\n",
    "# print(fil.fp_rate())\n",
    "# print(repr(fil))\n",
    "fA = BloomFilter.create_filter(0.00001, 1000)\n",
    "fB = BloomFilter.create_filter(0.00001, 1000, 16)\n",
    "fset = set()\n",
    "\n",
    "for _ in range(1000):\n",
    "    word = random_string().encode()\n",
    "    fset.add(word)\n",
    "    fA.add(word)\n",
    "    fB.add(word)\n",
    "\n",
    "print(repr(fA), f'fp={fA.fp_rate()}')\n",
    "print(repr(fB), f'fp={fB.fp_rate()}')\n",
    "\n",
    "print(sys.getsizeof(fset))\n",
    "# print(BloomFilter.least_memory(0.11, 1000))\n",
    "# mistakes = 0\n",
    "# total = 1000000\n",
    "# for _ in range(total):\n",
    "#     while True:\n",
    "#         word = random_string().encode()\n",
    "#         if word not in all_strings:\n",
    "#             break\n",
    "\n",
    "#     if word in fil:\n",
    "#         mistakes += 1\n",
    "\n",
    "# print(mistakes / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BloomFilter(n=23983B, #=0, k=14)\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "filt = BloomFilter.create_filter(0.0001, 10_000)\n",
    "\n",
    "print(repr(filt))\n",
    "\n",
    "filt.add(b\"www.youtube.com\")\n",
    "filt.add(b\"www.bbc.com\")\n",
    "\n",
    "print(b\"www.youtube.com\" in filt)\n",
    "print(b\"www.google.com\" in filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
